{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.docstore import Wikipedia\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "# openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "# openai.api_type = 'azure'\n",
    "# openai.api_version = '2023-05-15' # this may change in the future\n",
    "from langchain.llms import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=pathlib.Path('')) # \".env\"\n",
    "\n",
    "llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") #gpt-3.5-turbo-16k # \n",
    "#os.environ['OPENAI_API_KEY'] = \n",
    "# llm = AzureOpenAI(\n",
    "#     deployment_name=\"gpt-35-turbo-16k\",\n",
    "#     model_name=\"gpt-35-turbo-16k\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"./demo_app\", glob=\"**/*.*\", show_progress=True, use_multithreading=True, loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = hf\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "\n",
    "class Docstore:\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "\n",
    "    def list_files(self, *args, **kwargs):\n",
    "        \"\"\"List all files in the document store recursively.\"\"\"\n",
    "        all_files = []\n",
    "        for dirpath, dirnames, filenames in os.walk(self.folder_path):\n",
    "            for filename in filenames:\n",
    "                all_files.append(os.path.join(dirpath, filename))\n",
    "        return all_files\n",
    "\n",
    "    def read_file(self, filepath):\n",
    "        \"\"\"Read the content of a specific file.\"\"\"\n",
    "        filepath = filepath.replace(\"'\", \"\")\n",
    "        with open(filepath, 'rb') as file:\n",
    "            return file.read()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def create_ticket(title: str, description: str, affected_files=[]):\n",
    "    \"\"\"Create a ticket or code feature request as an output JSON file. with the given input parameters\"\"\"\n",
    "    output_folder = \"./tickets/\"\n",
    "    # Create a ticket dictionary with the provided details\n",
    "    ticket = {\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"affected_files\": affected_files,\n",
    "        \"status\": \"Open\"\n",
    "    }\n",
    "    \n",
    "    # Generate a unique filename based on the title\n",
    "    filename = title.replace(\" \", \"_\") + \".json\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "    \n",
    "    # Write the ticket to a JSON file\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(ticket, file, indent=4)\n",
    "    \n",
    "    return f\"Ticket saved to {filepath}\"\n",
    "\n",
    "docstore = Docstore(folder_path=\"./demo_app/backend/app/app/\")\n",
    "\n",
    "# tools.append(\n",
    "#     Tool(\n",
    "#         name=\"ListFiles\",\n",
    "#         func=docstore.list_files,\n",
    "#         description=\"Lists all txt files in the document store.\",\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# tools.append(\n",
    "#     Tool(\n",
    "#         name=\"ReadFile\",\n",
    "#         func=docstore.read_file,\n",
    "#         description=\"Reads the content of a specific code file.\",\n",
    "#     )\n",
    "# )\n",
    "\n",
    "ticket_tool = StructuredTool.from_function(create_ticket)\n",
    "\n",
    "\n",
    "\n",
    "tools.append(\n",
    "    ticket_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "vector_store_tool = Tool(\n",
    "    name=\"Code repository\",\n",
    "    func=repo.__call__,\n",
    "    description=\"useful for when you need to answer questions about code files within the repo. Input should be a fully formed question about what code files to search.\",\n",
    ")\n",
    "tools.append(vector_store_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_lead_agent_system_prompt: str = \"\"\"\n",
    "You are a tech lead, you have access to multiple repos, given a feature request, your job is to go through the code files and create a list of tickets for a software engineer to work on\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react = initialize_agent(tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_request: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_prompt_template: str = \"\"\"\n",
    "Langchain Agent:\n",
    "\n",
    "Given the repository's vector store containing all source code files, analyze the following user request:\n",
    "\n",
    "allow user to change password\n",
    "\n",
    "Your objective is to critically evaluate the repository to determine which files will be affected by the above request. Based on your analysis, create a set of tickets/issues that outline distinct units of work. Each ticket should:\n",
    "\n",
    "1. Describe the specific work to be done.\n",
    "2. Detail the changes required.\n",
    "3. List the relevant files that will be impacted.\n",
    "\n",
    "Ensure that each ticket is clear and concise, providing enough information for a software engineer to understand and implement the necessary changes.\n",
    "\n",
    "Once you've created the tickets, save them to the designated ticketing system or location for future reference and action by the engineering team.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react.run(\n",
    "    request_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"poetry\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
